accelerate==0.31.0        # via -r requirements.in
bitsandbytes==0.46.0      # via -r requirements.in
certifi==2025.4.26        # via requests
charset-normalizer==3.4.2  # via requests
diskcache==5.6.3          # via llama-cpp-python
filelock==3.18.0          # via huggingface-hub, torch, transformers
fsspec==2025.5.1          # via huggingface-hub, torch
hf-xet==1.1.3             # via huggingface-hub
huggingface-hub==0.33.0   # via accelerate, tokenizers, transformers
idna==3.10                # via requests
jinja2==3.1.6             # via llama-cpp-python, torch
llama-cpp-python==0.3.9   # via -r requirements.in
markupsafe==3.0.2         # via jinja2
mpmath==1.3.0             # via sympy
networkx==3.5             # via torch
numpy==2.3.0              # via -r requirements.in, accelerate, bitsandbytes, llama-cpp-python, transformers
nvidia-cublas-cu12==12.1.3.1  # via nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch
nvidia-cuda-cupti-cu12==12.1.105  # via torch
nvidia-cuda-nvrtc-cu12==12.1.105  # via torch
nvidia-cuda-runtime-cu12==12.1.105  # via torch
nvidia-cudnn-cu12==8.9.2.26  # via torch
nvidia-cufft-cu12==11.0.2.54  # via torch
nvidia-curand-cu12==10.3.2.106  # via torch
nvidia-cusolver-cu12==11.4.5.107  # via torch
nvidia-cusparse-cu12==12.1.0.106  # via nvidia-cusolver-cu12, torch
nvidia-nccl-cu12==2.20.5  # via torch
nvidia-nvjitlink-cu12==12.9.86  # via nvidia-cusolver-cu12, nvidia-cusparse-cu12
nvidia-nvtx-cu12==12.1.105  # via torch
packaging==25.0           # via accelerate, huggingface-hub, transformers
psutil==7.0.0             # via accelerate
pyyaml==6.0.2             # via accelerate, huggingface-hub, transformers
regex==2024.11.6          # via transformers
requests==2.32.4          # via huggingface-hub, transformers
safetensors==0.5.3        # via accelerate, transformers
sympy==1.14.0             # via torch
tokenizers==0.19.1        # via transformers
torch==2.3.1              # via -r requirements.in, accelerate, bitsandbytes
tqdm==4.67.1              # via huggingface-hub, transformers
transformers==4.41.2      # via -r requirements.in
typing-extensions==4.14.0  # via huggingface-hub, llama-cpp-python, torch
urllib3==2.4.0            # via requests
