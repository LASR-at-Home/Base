#!/usr/bin/env python3
import rospy
from typing import List
from lasr_vision_clip.clip_utils import load_model, query_image
from lasr_vision_msgs.srv import VqaRequest, VqaResponse, Vqa
from sensor_msgs.msg import Image


class VqaService:
    def __init__(self, model_device: str = "cuda") -> None:
        """Caches the clip model.

        Args:
            model_device (str, optional): device to load model onto. Defaults to "cuda".

        """

        self._model = load_model(model_device)
        self._debug_pub = rospy.Publisher("/clip_vqa/debug", Image, queue_size=1)
        rospy.loginfo("Clip VQA service started")

    def query_clip(self, request: VqaRequest) -> VqaResponse:
        """Queries CLIP from the robot's image stream and returns
        the most likely answer and cosine similarity score.

        Args:
            possible_answers (List[str]): set of possible answers.

        Returns:
            VqaResult
        """
        possible_answers = request.possible_answers
        answer, cos_score, annotated_img = query_image(
            request.image_raw, self._model, possible_answers, annotate=True
        )

        self._debug_pub.publish(annotated_img)

        result = VqaResponse()
        result.answer = answer
        rospy.loginfo(f"Answer: {answer}")
        result.similarity = float(cos_score)
        return result


if __name__ == "__main__":
    rospy.init_node("clip_vqa_service")
    service = VqaService()
    rospy.Service("/clip_vqa/query_service", Vqa, service.query_clip)
    rospy.spin()
