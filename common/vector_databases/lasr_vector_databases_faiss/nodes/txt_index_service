#!/usr/bin/env python3
import rospy
import numpy as np
from lasr_vector_databases_msgs.srv import TxtIndexRequest, TxtIndexResponse, TxtIndex
from lasr_vector_databases_faiss import (
    load_model,
    parse_txt_file,
    get_sentence_embeddings,
    construct_faiss_index,
    add_vectors_to_index,
    save_index_to_disk,
)
from typing import List


class TxtIndexService:
    def __init__(self):
        rospy.init_node("txt_index_service")
        rospy.Service("lasr_faiss/txt_index", TxtIndex, self.execute_cb)
        self._sentence_embedding_model = load_model()
        rospy.loginfo("Text index service started")

    def execute_cb(self, req: TxtIndexRequest):
        txt_fps: List[str] = req.txt_paths
        index_paths: List[str] = req.index_paths
        factory_string: str = req.index_factory_string
        vecs_per_txt_file: List[int] = []
        n_train_vecs = 5000000
        if len(index_paths) == 1 and len(txt_fps) > 1:
            xn = np.memmap(
                f"/tmp/xn.dat",
                dtype="float32",
                mode="w+",
                shape=(8403420, 384),
            )
            for i, txt_fp in enumerate(txt_fps):
                sentences_to_embed: List[str] = parse_txt_file(txt_fp)
                sentence_embeddings: np.ndarray = get_sentence_embeddings(
                    sentences_to_embed, self._sentence_embedding_model
                )
                if i == 0:
                    index = construct_faiss_index(
                        index_factory_string=factory_string,
                        vector_dim=sentence_embeddings.shape[1],
                    )
                    xt = np.empty(
                        (n_train_vecs, sentence_embeddings.shape[1]), dtype=np.float32
                    )
                sentences_for_training = sentence_embeddings[:100000]
                xt[i * 100000 : (i + 1) * 100000] = sentences_for_training
                xn[
                    i
                    * sentence_embeddings.shape[0] : (i + 1)
                    * sentence_embeddings.shape[0],
                ] = sentence_embeddings
                vecs_per_txt_file.append(sentence_embeddings.shape[0])
            rospy.loginfo("Training index")
            index.train(xt)
            rospy.loginfo("Adding vectors to index")
            add_vectors_to_index(index, xn)
            rospy.loginfo("Saving index to disk")
            save_index_to_disk(index, index_paths[0])

        elif len(index_paths) != len(txt_fps):
            rospy.logerr(
                "Number of txt files and index paths must be the same, or only one index "
                "path must be provided."
                f"Got {len(txt_fps)} txt files and {len(index_paths)} index paths."
            )
        else:
            for txt_fp, index_path in zip(txt_fps, index_paths):
                sentences_to_embed: list[str] = parse_txt_file(txt_fp)
                sentence_embeddings: np.ndarray = get_sentence_embeddings(
                    sentences_to_embed, self._sentence_embedding_model
                )
                index = construct_faiss_index(
                    index_factory_string=factory_string,
                    vector_dim=sentence_embeddings.shape[1],
                )
                add_vectors_to_index(index, sentence_embeddings)
                save_index_to_disk(index, index_path)
                vecs_per_txt_file.append(sentence_embeddings.shape[0])

        return TxtIndexResponse(vecs_per_txt_file=vecs_per_txt_file)


if __name__ == "__main__":
    TxtIndexService()
    rospy.spin()
