#!/usr/bin/env python3

import rospy

from qualification.msg import DetectPeopleAction, DetectPeopleResult
from actionlib import SimpleActionServer
from tf_module.srv import TfTransform, TfTransformRequest
from common_math import pcl_msg_to_cv2, seg_to_centroid
from cv_bridge3 import CvBridge
from sensor_msgs.msg import PointCloud2
from geometry_msgs.msg import PointStamped, Point
from std_msgs.msg import String

from lasr_vision_msgs.srv import YoloDetection
import numpy as np


class DetectPeople:

    def __init__(self):

        self.yolo = rospy.ServiceProxy("/yolov8/detect", YoloDetection)
        self.tf = rospy.ServiceProxy("/tf_transform", TfTransform)
        self.bridge = CvBridge()

        self._action_server = SimpleActionServer(
            "detect_people",
            DetectPeopleAction,
            execute_cb=self.execute_cb,
            auto_start=False,
        )

        self._action_server.start()

    def estimate_pose(self, pcl_msg, detection):
        centroid_xyz = seg_to_centroid(pcl_msg, np.array(detection.xyseg))
        centroid = PointStamped()
        centroid.point = Point(*centroid_xyz)
        centroid.header = pcl_msg.header
        tf_req = TfTransformRequest()
        tf_req.target_frame = String("map")
        tf_req.point = centroid
        response = self.tf(tf_req)
        return response.target_point.point

    def execute_cb(self, _):
        pcl_msg = rospy.wait_for_message("/xtion/depth_registered/points", PointCloud2)
        cv_im = pcl_msg_to_cv2(pcl_msg)
        img_msg = self.bridge.cv2_to_imgmsg(cv_im)
        yolo_result = self.yolo(img_msg, "yolov8n-seg.pt", 0.5, 0.3)
        result = DetectPeopleResult()
        result.points = [
            self.estimate_pose(pcl_msg, detection)
            for detection in yolo_result.detected_objects
        ]

        self._action_server.set_succeeded(result)


if __name__ == "__main__":
    rospy.init_node("detect_people")
    DetectPeople()
    rospy.spin()
