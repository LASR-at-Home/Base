#!/usr/bin/env python3

"""
begin in kitchen area
1. A greets robot (hi tiago)
2. Robot doesn't know who A is, so asks for their name
3. Robot learns A's face, tells them it's done
4. A asks robot to guide them to the lab 
5. Robot guides A to the lab, we mark the corners as landmarks, where the robot has to turn around and check that the person is still following. If they're not, the robot can go back around the corner and try again.
6. Robot says "we're here" and stops
7. A asks robot to find B (known person), A thinks that B needs assistance.
8. Robot finds B, asks them if they need assistance
9. B asks robot to pick up object X
10. Robot picks up object X, brings it to B
12. Robot hands object X to B

Visualisation:
- audio -> transcription -> command look-up -> action
- navigation (planning)
- face recognition
- object, person detection
- grasping
"""
import rospy
import rospkg
import os


rospy.init_node("clip_test")
import qualification.clip_utils as clip_utils

model = clip_utils.load_model()
print(
    clip_utils.vqa(
        model,
        [
            "a person pointing with their left arm",
            "a person not pointing with their left arm",
        ],
    )[0]
)
