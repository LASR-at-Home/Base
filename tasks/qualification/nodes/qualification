#!/usr/bin/env python3

"""
begin in kitchen area
1. A greets robot (hi tiago)
2. Robot doesn't know who A is, so asks for their name
3. Robot learns A's face, tells them it's done
4. A asks robot to guide them to the lab 
5. Robot guides A to the lab, we mark the corners as landmarks, where the robot has to turn around and check that the person is still following. If they're not, the robot can go back around the corner and try again.
6. Robot says "we're here" and stops
7. A asks robot to find B (known person), A thinks that B needs assistance.
8. Robot finds B, asks them if they need assistance
9. B asks robot to pick up object X
10. Robot picks up object X, brings it to B
12. Robot hands object X to B

Visualisation:
- audio -> transcription -> command look-up -> action
- navigation (planning)
- face recognition
- object, person detection
- grasping
"""
import rospy
import rospkg
import os

COMMAND_ROOT = os.path.join(rospkg.RosPack().get_path("qualification"), "data")

rospy.init_node("qualification")
from lasr_vision_msgs.srv import (
    Recognise,
    RecogniseRequest,
    LearnFace,
    LearnFaceRequest,
)
from sensor_msgs.msg import Image
from lasr_voice import Voice
from std_srvs.srv import Empty

import actionlib
from lasr_speech_recognition_msgs.srv import TranscribeAudio, TranscribeAudioResponse
from lasr_speech_recognition_msgs.msg import (
    TranscribeSpeechAction,
    TranscribeSpeechGoal,
)
from tiago_controllers.controllers import BaseController

import random

import qualification.command_similarity as command_similarity

from geometry_msgs.msg import Pose, Quaternion, Point

voice = Voice()
rospy.loginfo("Got voice")
recognise = rospy.ServiceProxy("/recognise", Recognise)
recognise.wait_for_service()
rospy.loginfo("Got recognise")
learn_face = rospy.ServiceProxy("/learn_face", LearnFace)
learn_face.wait_for_service()
rospy.loginfo("Got learn_face")
transcribe = actionlib.SimpleActionClient("transcribe_speech", TranscribeSpeechAction)
transcribe.wait_for_server()
rospy.loginfo("Got transcribe_speech")
base_controller = BaseController()
rospy.loginfo("Got base_controller")


def do_recognise(image):
    req = RecogniseRequest()
    req.image_raw = image
    req.dataset = "qualification"
    req.confidence = 0.7
    resp = recognise(req)
    return resp.detections


def do_transcribe_speech():
    transcribe.send_goal(TranscribeSpeechGoal())
    transcribe.wait_for_result()
    result = transcribe.get_result()
    return result.sequence.lower()


pre_door_pose = Pose(
    position=Point(4.15944400458617, 8.87898068920585, 0.0),
    orientation=Quaternion(0.0, 0.0, -0.5685040400615354, 0.8226804704341244),
)

door_wait_pose = Pose(
    position=Point(3.5908463546596536, 8.55637964340359, 0.0),
    orientation=Quaternion(0.0, 0.0, -0.40530666046961816, 0.9141807868135086),
)


lab_pose = Pose(
    position=Point(4.564212770348313, 7.033843500398589, 0.0),
    orientation=Quaternion(0.0, 0.0, -0.7733597054145271, 0.6339674802709961),
)


def greet():
    # TODO: greet the person, if they are not in the database, ask them to introduce themselves and learn their face
    im = rospy.wait_for_message("/xtion/rgb/image_raw", Image)
    face_recognition_result = do_recognise(im)
    if not face_recognition_result:
        # unknown person
        voice.speak("Hello, I don't know who you are. What is your name?")
        name = (
            do_transcribe_speech().replace(".", "").split(" ")[-1]
        )  # assume the last word is the name :)
        voice.speak(f"Thank you, {name}, I will remember your face now")
        # TODO: learn face and associate with name
        learn_face(name, "qualification", 50)
        # just perform an inference for visualisation purposes
        do_recognise(im)
        return name
    else:
        suffixes = [
            "it's great to see you again",
            "it's nice to see you",
            "it's good to see you",
        ]
        name = face_recognition_result[0].name
        voice.speak(
            f"Hello, {face_recognition_result[0].name} {random.choice(suffixes)}"
        )
    return name


def clear_costmap():
    """
    Clears costmap using clear_octomap server
    """

    rospy.loginfo("waiting for clear_costmap")
    rospy.wait_for_service("/move_base/clear_costmaps", timeout=10)
    try:
        _clear_costmap = rospy.ServiceProxy("/move_base/clear_costmaps", Empty)
        response = _clear_costmap()
        rospy.loginfo("clearing costmap done!")
        return response
    except rospy.ServiceException as e:
        print("Service call failed: %s" % e)


def guide(name):
    voice.speak(f"Follow me, {name}, I will take you to the lab.")
    # TODO: guide person to the lab, at landmarks, check if they are still following, if they're not, look for them
    base_controller.sync_to_pose(pre_door_pose)
    # wait for the door to open
    voice.async_tts(f"{name}, could you open the door for me please?")
    base_controller.sync_to_pose(door_wait_pose)
    base_controller.sync_to_pose(lab_pose)


def end():
    pass


def offer_assistance(name):
    voice.speak(f"Hello, {name}, do you need any assistance")
    while True:
        command = do_transcribe_speech()
        if "that is all" in command:
            voice.speak("Goodbye")
            end()
            break
        nearest_commands, distances = command_similarity.get_similar_commands(
            command,
            os.path.join(COMMAND_ROOT, "command_index"),
            os.path.join(COMMAND_ROOT, "command_list.txt"),
        )
        voice.speak(f"Did you mean {nearest_commands[0]}?")
        speech = do_transcribe_speech()
        if "yes" in speech:
            command = nearest_commands[0]
            break
        else:
            voice.speak("Sorry, could you please repeat that for me?")


# Phase 1: wait for a person to greet the robot
while not rospy.is_shutdown():
    speech = do_transcribe_speech()
    if "hello" in speech or "hi" in speech:
        name = greet()
        break

# # Phase 2: receive command from person
voice.speak(f"What can I do for you {name}?")
while True:
    command = do_transcribe_speech()
    if "that is all" in command:
        voice.speak("Goodbye")
        end()
        break
    nearest_commands, distances = command_similarity.get_similar_commands(
        command,
        os.path.join(COMMAND_ROOT, "command_index"),
        os.path.join(COMMAND_ROOT, "command_list.txt"),
    )
    voice.speak(f"Did you mean {nearest_commands[0]}?")
    speech = do_transcribe_speech()
    if "yes" in speech:
        command = nearest_commands[0]
        break
    else:
        voice.speak("Sorry, could you please repeat that for me?")


if "guide" in command:
    guide(name)

while True:
    command = do_transcribe_speech()
    nearest_commands, distances = command_similarity.get_similar_commands(
        command,
        os.path.join(COMMAND_ROOT, "command_index"),
        os.path.join(COMMAND_ROOT, "command_list.txt"),
    )
    voice.speak(f"Did you mean {nearest_commands[0]}?")
    speech = do_transcribe_speech()
    if "yes" in speech:
        command = nearest_commands[0]
        break
    else:
        voice.speak("Sorry, could you please repeat that for me?")


# if "guide" in command:
#     guide()


# Phase 2: guide the person to the lab, for now just go to the lab, assume the person is following
